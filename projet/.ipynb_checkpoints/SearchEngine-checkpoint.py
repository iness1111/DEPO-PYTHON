import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.metrics.pairwise import cosine_similarity
from collections import Counter
# from tqdm import tqdm
from stqdm import stqdm
import time

class SearchEngine:

    def __init__(self, corpus, stop_words=None, use_tfidf=True):
        """
        we initialize the search engine:
        - build vocab + build TF matrix + compute vocab stats (TF + DF) + build TF-IDF matrix
        """
        self.corpus = corpus
        self.stop_words = stop_words if stop_words else set()
        self.use_tfidf = use_tfidf

        # build vocabulary
        self.vocab = corpus.build_vocab_dict(stop_words=self.stop_words)

        # build TF matrix
        self.mat_TF, self.vocab = corpus.build_TF_matrix(stop_words=self.stop_words)

        # update vocabulary stats
        self.vocab = corpus.update_vocab_stats(self.mat_TF, self.vocab)

        # build TF-IDF matrix
        self.mat_TF_IDF = corpus.build_TF_IDF_matrix(self.mat_TF, self.vocab)

        # column index in matrix
        self.word_to_col = {w: info["id"] - 1 for w, info in self.vocab.items()}

        print("SearchEngine initialized:")
        print(f"- vocab size: {len(self.vocab)}")
        print(f"- matrix shape: {self.mat_TF.shape}")

    def search(self, query, k=10): # recherche dans documents par mots cl√©s dans req
        query = self.corpus.nettoyer_texte(query)
        tokens = query.split()
        tokens = [w for w in tokens if w in self.vocab]
    
        if not tokens:
            return pd.DataFrame({"message": ["No query terms found in vocabulary"]})
    
        # creation query vector de requete
        q_vec = np.zeros(len(self.vocab))
        for w in tokens:
            q_vec[self.word_to_col[w]] += 1
        q_vec = csr_matrix(q_vec)
        doc_matrix = self.mat_TF_IDF if self.use_tfidf else self.mat_TF
    
        # Cosine similarity
        sims = cosine_similarity(q_vec, doc_matrix).flatten()
    
        # Top-k ranking 
        top_idx = sims.argsort()[::-1][:k]
    
        rows = []
    
        for idx in top_idx:
            doc_id = idx + 1
            doc = self.corpus.id2doc[doc_id]
    
            concord_text = self.corpus.concord(
                doc_id,
                query_words=tokens,
                window=50
            )
    
            rows.append({
                "doc_id": doc_id,
                "titre": doc.titre,
                "auteur": doc.auteur,
                "date": doc.date,
                "score": sims[idx],
                "url": getattr(doc, "url", ""),
                "texte": concord_text
            })
    
        return pd.DataFrame(rows)
